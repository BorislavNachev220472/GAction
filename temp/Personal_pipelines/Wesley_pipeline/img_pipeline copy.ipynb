{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "from patchify import patchify, unpatchify\n",
    "from tensorflow.keras.models import load_model\n",
    "from skan import Skeleton, summarize\n",
    "from skimage.morphology import skeletonize\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_dataset = \"Input\"\n",
    "Save_results_as = \"Results_root_len.csv\"\n",
    "\n",
    "model_location = \"Wesley_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img):\n",
    "    \"\"\" Crops an image based on edge detection using Canny.\n",
    "\n",
    "    Args:\n",
    "        image_name (str): The filename of the image to be processed.\n",
    "    \n",
    "    returns:\n",
    "        output_image, diff_output_height, diff_output_width, y1, y2, x1, x2\n",
    "        output_image(ndarray): The cropped image\n",
    "        diff_output_height(int): the difference in height and width\n",
    "        diff_output_width(int): the difference in width and height\n",
    "        y1(int): the upper left corner of the edge\n",
    "        y2(int): the down left corner of the edge\n",
    "        x1(int): the upper right corner of the edge\n",
    "        x2(int): the down right corner of the edge\n",
    "    \"\"\"\n",
    "        \n",
    "\n",
    "    input_image = img[:, 0:4100]\n",
    "\n",
    "    canny = cv2.Canny(input_image, 0, 255)\n",
    "\n",
    "    pts = np.argwhere(canny > 0)\n",
    "    y1, x1 = pts.min(axis=0)\n",
    "    y2, x2 = pts.max(axis=0)\n",
    "\n",
    "    output_image = input_image[y1:y2, x1:x2]\n",
    "    output_height = output_image.shape[0]\n",
    "    output_width = output_image.shape[1]\n",
    "    difference = abs(output_height - output_width)\n",
    "\n",
    "    if output_height > output_width:\n",
    "        diff_output_height = output_height - difference\n",
    "        diff_output_width = output_width\n",
    "    if output_height < output_width:\n",
    "        diff_output_width = output_width - difference\n",
    "        diff_output_height = output_height\n",
    "\n",
    "    output_image = output_image[0:diff_output_height, 0:diff_output_width]\n",
    "    return(output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_fix(img):\n",
    "    \"\"\"\n",
    "    Fix errors in an input image.\n",
    "\n",
    "    This function takes an input image and performs the following operations to fix errors:\n",
    "    1. Adjust the image dimensions to be square by cropping from the sides if necessary.\n",
    "    2. Apply the 'crop_img' function twice to further crop the image.\n",
    "\n",
    "    Parameters:\n",
    "    img (numpy.ndarray): The input image as a NumPy array.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The fixed image after error correction.\n",
    "    \"\"\"\n",
    "    diff_shape = round((img.shape[1] - img.shape[0]) / 2)\n",
    "    diff_shape_1 = img.shape[1] - diff_shape\n",
    "    img = img[:, diff_shape:diff_shape_1]\n",
    "    output_img_temp = crop_img(img)\n",
    "    output_img = crop_img(output_img_temp)\n",
    "    return(output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padder(image, patch_size):\n",
    "    \"\"\"\n",
    "    Adds padding to an image to make its dimensions divisible by a specified patch size.\n",
    "\n",
    "    This function calculates the amount of padding needed for both the height and width of an image so that its dimensions become divisible by the given patch size. The padding is applied evenly to both sides of each dimension (top and bottom for height, left and right for width). If the padding amount is odd, one extra pixel is added to the bottom or right side. The padding color is set to black (0, 0, 0).\n",
    "\n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): The input image as a NumPy array. Expected shape is (height, width, channels).\n",
    "    - patch_size (int): The patch size to which the image dimensions should be divisible. It's applied to both height and width.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: The padded image as a NumPy array with the same number of channels as the input. Its dimensions are adjusted to be divisible by the specified patch size.\n",
    "\n",
    "    Example:\n",
    "    - padded_image = padder(cv2.imread('example.jpg'), 128)\n",
    "\n",
    "    \"\"\"\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "    height_padding = ((h // patch_size) + 1) * patch_size - h\n",
    "    width_padding = ((w // patch_size) + 1) * patch_size - w\n",
    "\n",
    "    top_padding = int(height_padding/2)\n",
    "    bottom_padding = height_padding - top_padding\n",
    "\n",
    "    left_padding = int(width_padding/2)\n",
    "    right_padding = width_padding - left_padding\n",
    "\n",
    "    padded_image = cv2.copyMakeBorder(image, top_padding, bottom_padding, left_padding, right_padding, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "        total = K.sum(K.square(y_true),[1,2,3]) + K.sum(K.square(y_pred),[1,2,3])\n",
    "        union = total - intersection\n",
    "        return (intersection + K.epsilon()) / (union + K.epsilon())\n",
    "    return K.mean(f(y_true, y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_predictor(img, root_thr, model_type):\n",
    "    \"\"\"\n",
    "    Predicts root presence in an image using a pre-trained model.\n",
    "\n",
    "    This function takes an image and applies a pre-trained model to predict root presence. \n",
    "    It supports two model types, each with different preprocessing requirements. \n",
    "    The image is first padded, then split into patches, which are fed into the model for prediction. \n",
    "    The predictions are then reconstructed into a single image. The output is a binary mask representing \n",
    "    the predicted root presence and the original (or processed) image.\n",
    "\n",
    "    Parameters:\n",
    "    img (ndarray): The input image. Should be a NumPy array, format depending on model_type.\n",
    "    root_thr (float): Threshold for converting the model's output to a binary mask. \n",
    "                      Values above this threshold are considered as root presence.\n",
    "    model_type (int): Indicator of the model type to use. \n",
    "                      1 for the first model, 2 for the second model.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - predicted_root (ndarray): A binary mask of the same size as `img`, \n",
    "          indicating the presence of roots (1 for root, 0 for no root).\n",
    "        - img (ndarray): The original or processed image, depending on `model_type`.\n",
    "\n",
    "    Raises:\n",
    "    Exception: If `model_type` is not 1 or 2, or other exceptions related to \n",
    "               loading models, image processing, or prediction.\n",
    "\n",
    "    Note:\n",
    "    This function requires certain external functions and models to be loaded:\n",
    "    - `load_model` from an external library to load the pre-trained model.\n",
    "    - `f1`, `iou` custom objects, likely used in the model.\n",
    "    - `padder`, `patchify`, `unpatchify` for image preprocessing.\n",
    "    - `cv2` for image manipulation.\n",
    "    \"\"\"\n",
    "    \n",
    "    if model_type == 1:\n",
    "        root_mask_model = load_model('task_4_binary/models/all_trained_data_aug2.h5', custom_objects={'f1': f1, 'iou':iou})\n",
    "    elif model_type == 2:\n",
    "        root_mask_model = load_model(model_location, custom_objects={'f1': f1, 'iou':iou})\n",
    "    img = padder(img, 256)\n",
    "\n",
    "    if model_type == 1:\n",
    "        patches = patchify(img, (256, 256, 3), step=256)\n",
    "    if model_type == 2:\n",
    "        patches = patchify(img, (256, 256), step=256)\n",
    "    i = patches.shape[0]\n",
    "    j = patches.shape[1]\n",
    "    if model_type == 1:\n",
    "        patches = patches.reshape(-1, 256, 256, 3)\n",
    "    if model_type == 2:\n",
    "        patches = patches.reshape(-1, 256, 256, 1)\n",
    "    preds_root = root_mask_model.predict(patches/255)\n",
    "    preds_root = preds_root.reshape(i, j, 256, 256)\n",
    "    predicted_root = unpatchify(preds_root, (img.shape[0], img.shape[1]))\n",
    "    predicted_root = predicted_root>root_thr\n",
    "    predicted_root = predicted_root.astype(int)\n",
    "    predicted_root = cv2.convertScaleAbs(predicted_root) \n",
    "\n",
    "    return(predicted_root, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmanter(predicted_root, img):\n",
    "    \n",
    "    \"\"\"\n",
    "    Segments the largest objects in different regions of an image based on a binary mask.\n",
    "\n",
    "    This function takes a binary mask (predicted_root) indicating the presence of certain objects\n",
    "    (e.g., roots in an image) and segments the largest objects in predefined regions of the mask. \n",
    "    The regions are based on the width of the image. It then extracts these objects from both the \n",
    "    binary mask and the original image. The function also plots the segmentation results for visualization.\n",
    "\n",
    "    Parameters:\n",
    "    predicted_root (ndarray): A binary mask image, where 1 represents the presence of an object.\n",
    "    img (ndarray): The original image corresponding to the binary mask.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - full_imgs (list of ndarray): Segmented objects from the binary mask.\n",
    "        - real_imgs (list of ndarray): Corresponding segmented objects from the original image.\n",
    "        - object_presence (ndarray): A binary array indicating the presence of objects in each region.\n",
    "        - x (list of int): The x-coordinate of the top-left corner of each segmented object.\n",
    "        - y (list of int): The y-coordinate of the top-left corner of each segmented object.\n",
    "        - w (list of int): The width of each segmented object.\n",
    "        - h (list of int): The height of each segmented object.\n",
    "\n",
    "    Note:\n",
    "    - The function splits the image into 5 regions based on width and segments the largest object in each region.\n",
    "    - It uses `cv2.connectedComponentsWithStats` for segmentation.\n",
    "    - Plots are created using `matplotlib.pyplot`.\n",
    "    - This function assumes certain threshold values and dimensions specific to the use case.\n",
    "    \"\"\"\n",
    "     \n",
    "\n",
    "    label_count, labels, stats, centroids = cv2.connectedComponentsWithStats(predicted_root)\n",
    "\n",
    "    topmost_coordinates = np.full((label_count, 2), (0, labels.shape[0]), dtype=int)\n",
    "    \n",
    "    for y in range(labels.shape[0]):\n",
    "        for x in range(labels.shape[1]):\n",
    "            label = labels[y, x]\n",
    "            if label != 0:  # Ignore the background\n",
    "                if y < topmost_coordinates[label][1]:\n",
    "                    topmost_coordinates[label] = [x, y]\n",
    "\n",
    "    # Remove the entry for the background\n",
    "    topmost_coordinates = topmost_coordinates[1:]\n",
    "\n",
    "    large = []\n",
    "    th_1 = np.sum(predicted_root[300:2500, 0:600]) * 0.1\n",
    "    th_2 = np.sum(predicted_root[300:2500, 600:1200]) * 0.1\n",
    "    th_3 = np.sum(predicted_root[300:2500, 1200:1600]) * 0.1\n",
    "    th_4 = np.sum(predicted_root[300:2500, 1600:2200]) * 0.1\n",
    "    th_5 = np.sum(predicted_root[300:2500, 2200:]) * 0.1\n",
    "\n",
    "    image_width = predicted_root.shape[1]\n",
    "\n",
    "    largest_area_1 = 0\n",
    "    largest_area_2 = 0\n",
    "    largest_area_3 = 0\n",
    "    largest_area_4 = 0\n",
    "    largest_area_5 = 0\n",
    "\n",
    "    largest_label_1 = -1\n",
    "    largest_label_2 = -1\n",
    "    largest_label_3 = -1\n",
    "    largest_label_4 = -1\n",
    "    largest_label_5 = -1\n",
    "\n",
    "    object_presence = np.zeros(5)\n",
    "\n",
    "\n",
    "    for x in range(1, label_count):\n",
    "        if (\n",
    "            stats[x, cv2.CC_STAT_TOP] < 1500\n",
    "            and stats[x, cv2.CC_STAT_LEFT] >= 10\n",
    "            and stats[x, cv2.CC_STAT_LEFT] + stats[x, cv2.CC_STAT_WIDTH] <= image_width - 10\n",
    "            and stats[x, cv2.CC_STAT_TOP] > 200\n",
    "            and stats[x, cv2.CC_STAT_AREA] > 100\n",
    "            \n",
    "        ):\n",
    "            if stats[x, cv2.CC_STAT_TOP] < 600 or stats[x, cv2.CC_STAT_AREA] > 3000:\n",
    "                if (\n",
    "                    stats[x, cv2.CC_STAT_AREA] > th_1\n",
    "                    and topmost_coordinates[x-1][0] < 600\n",
    "                ):\n",
    "                    area_1 = stats[x, cv2.CC_STAT_AREA]\n",
    "                    if area_1 > largest_area_1:\n",
    "                        largest_area_1 = area_1\n",
    "                        largest_label_1 = x\n",
    "\n",
    "                if (\n",
    "                    stats[x, cv2.CC_STAT_AREA] > th_2\n",
    "                    and topmost_coordinates[x-1][0] > 600\n",
    "                    and topmost_coordinates[x-1][0] < 1200\n",
    "                ):\n",
    "                    area_2 = stats[x, cv2.CC_STAT_AREA]\n",
    "                    if area_2 > largest_area_2:\n",
    "                        largest_area_2 = area_2\n",
    "                        largest_label_2 = x\n",
    "\n",
    "\n",
    "                if (\n",
    "                    stats[x, cv2.CC_STAT_AREA] > th_3\n",
    "                    and topmost_coordinates[x-1][0] > 1200\n",
    "                    and topmost_coordinates[x-1][0] < 1700\n",
    "                ):\n",
    "                    area_3 = stats[x, cv2.CC_STAT_AREA]\n",
    "                    if area_3 > largest_area_3:\n",
    "                        largest_area_3 = area_3\n",
    "                        largest_label_3 = x\n",
    "\n",
    "                if (\n",
    "                    stats[x, cv2.CC_STAT_AREA] > th_4\n",
    "                    and topmost_coordinates[x-1][0] > 1700\n",
    "                    and topmost_coordinates[x-1][0] < 2300\n",
    "                ):\n",
    "                    area_4 = stats[x, cv2.CC_STAT_AREA]\n",
    "                    if area_4 > largest_area_4:\n",
    "                        largest_area_4 = area_4\n",
    "                        largest_label_4 = x\n",
    "\n",
    "                if (\n",
    "                    stats[x, cv2.CC_STAT_AREA] > th_5\n",
    "                    and topmost_coordinates[x-1][0] > 2300\n",
    "                ):\n",
    "                    area_5 = stats[x, cv2.CC_STAT_AREA]\n",
    "                    if area_5 > largest_area_5:\n",
    "                        largest_area_5 = area_5\n",
    "                        largest_label_5 = x\n",
    "\n",
    "\n",
    "    if largest_label_1 != -1:\n",
    "        large.append(largest_label_1)\n",
    "        object_presence[0] = 1\n",
    "\n",
    "    if largest_label_2 != -1:\n",
    "        large.append(largest_label_2)\n",
    "        object_presence[1] = 1\n",
    "        \n",
    "    if largest_label_3 != -1:\n",
    "        large.append(largest_label_3)\n",
    "        object_presence[2] = 1\n",
    "    \n",
    "    if largest_label_4 != -1:\n",
    "        large.append(largest_label_4)\n",
    "        object_presence[3] = 1\n",
    "\n",
    "    if largest_label_5 != -1:\n",
    "        large.append(largest_label_5)\n",
    "        object_presence[4] = 1\n",
    "\n",
    "    black_img1 = np.zeros_like(labels, dtype=np.uint8)\n",
    "    for x, component_idx in enumerate(large):\n",
    "        color = x + 1\n",
    "        black_img1[labels == component_idx] = color\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    w = []\n",
    "    h = []\n",
    "\n",
    "    for i in large:\n",
    "        x.append(stats[i, 0])\n",
    "        y.append(stats[i, 1])\n",
    "        w.append(stats[i, 2])\n",
    "        h.append(stats[i, 3])\n",
    "\n",
    "\n",
    "    full_imgs = []\n",
    "    real_imgs = []\n",
    "\n",
    "    for i in range(len(large)):\n",
    "        full_imgs.append(black_img1[y[i]:y[i]+h[i], x[i]:x[i]+w[i]])\n",
    "        real_imgs.append(img[y[i]:y[i]+h[i], x[i]:x[i]+w[i]])\n",
    "\n",
    "    return(full_imgs, real_imgs, object_presence, x, y, w, h, black_img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_plant_segmanter(predicted_root, img, object_presence, predicted_root_2):\n",
    "    \"\"\"\n",
    "    Segments small plants in an image based on a binary mask and predefined zones.\n",
    "\n",
    "    This function focuses on segmenting small plants within specific zones of a binary mask. \n",
    "    It first applies a mask to preserve only the specified zones in the predicted_root image. \n",
    "    Then, it identifies and segments the largest object in each of these zones. The function \n",
    "    also creates visualizations showing the segmentation results.\n",
    "\n",
    "    Parameters:\n",
    "    predicted_root (ndarray): A binary mask image, with 1 representing the presence of an object (plant).\n",
    "    img (ndarray): The original image corresponding to the binary mask.\n",
    "    object_presence (ndarray): A binary array indicating the presence of objects in each region.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - full_imgs (list of ndarray): Segmented objects from the binary mask within the specified zones.\n",
    "        - real_imgs (list of ndarray): Corresponding segmented objects from the original image within the specified zones.\n",
    "        - object_presence (ndarray): Updated binary array indicating the presence of objects in each region after segmentation.\n",
    "        - x (list of int): The x-coordinate of the top-left corner of each segmented object.\n",
    "        - y (list of int): The y-coordinate of the top-left corner of each segmented object.\n",
    "        - w (list of int): The width of each segmented object.\n",
    "        - h (list of int): The height of each segmented object.\n",
    "\n",
    "    Note:\n",
    "    - The function defines specific zones (preserved areas) for segmentation.\n",
    "    - Uses `cv2.connectedComponentsWithStats` for segmentation.\n",
    "    - Visualization is created using `matplotlib.pyplot`.\n",
    "    - The function assumes a minimum area threshold for object segmentation.\n",
    "    \"\"\"\n",
    " \n",
    "    preserve_zones = [\n",
    "        (450, 550, 320, 400),     # Zone 1\n",
    "        (390, 500, 850, 950),     # Zone 2\n",
    "        (390, 500, 1350, 1450),   # Zone 3\n",
    "        (390, 500, 1900, 2000),   # Zone 4\n",
    "        (390, 500, 2400, 2500)    # Zone 5\n",
    "    ]\n",
    "\n",
    "    mask = np.zeros_like(predicted_root, dtype=bool)\n",
    "\n",
    "    for x_start, x_end, y_start, y_end in preserve_zones:\n",
    "        mask[x_start:x_end, y_start:y_end] = True\n",
    "\n",
    "    predicted_root[~mask] = 0\n",
    "\n",
    "\n",
    "\n",
    "    label_count, labels, stats, centroids = cv2.connectedComponentsWithStats(predicted_root)\n",
    "\n",
    "    large = []\n",
    "\n",
    "    largest_area_1 = 0\n",
    "    largest_area_2 = 0\n",
    "    largest_area_3 = 0\n",
    "    largest_area_4 = 0\n",
    "    largest_area_5 = 0\n",
    "\n",
    "    largest_label_1 = -1\n",
    "    largest_label_2 = -1\n",
    "    largest_label_3 = -1\n",
    "    largest_label_4 = -1\n",
    "    largest_label_5 = -1\n",
    "\n",
    "    object_presence = np.zeros(5)\n",
    "\n",
    "\n",
    "\n",
    "    for x in range(1, label_count):\n",
    "        if (stats [x, cv2.CC_STAT_AREA] > 7):\n",
    "            if ( stats[x, cv2.CC_STAT_LEFT] < 600\n",
    "                ):\n",
    "                area_1 = stats[x, cv2.CC_STAT_AREA]\n",
    "\n",
    "                if area_1 > largest_area_1:\n",
    "                    largest_area_1 = area_1\n",
    "                    largest_label_1 = x\n",
    "\n",
    "            if (\n",
    "                stats[x, cv2.CC_STAT_LEFT] > 600\n",
    "                and stats[x, cv2.CC_STAT_LEFT] < 1200\n",
    "                ):\n",
    "            \n",
    "                area_2 = stats[x, cv2.CC_STAT_AREA]\n",
    "                if area_2 > largest_area_2:\n",
    "                    largest_area_2 = area_2\n",
    "                    largest_label_2 = x\n",
    "\n",
    "\n",
    "            if (\n",
    "                stats[x, cv2.CC_STAT_LEFT] > 1200\n",
    "                and stats[x, cv2.CC_STAT_LEFT] < 1600\n",
    "            ):\n",
    "                area_3 = stats[x, cv2.CC_STAT_AREA]\n",
    "                if area_3 > largest_area_3:\n",
    "                    largest_area_3 = area_3\n",
    "                    largest_label_3 = x\n",
    "\n",
    "            if (\n",
    "                stats[x, cv2.CC_STAT_LEFT] > 1600\n",
    "                and stats[x, cv2.CC_STAT_LEFT] < 2100\n",
    "            ):\n",
    "                area_4 = stats[x, cv2.CC_STAT_AREA]\n",
    "                if area_4 > largest_area_4:\n",
    "                    largest_area_4 = area_4\n",
    "                    largest_label_4 = x\n",
    "\n",
    "            if (\n",
    "                stats[x, cv2.CC_STAT_LEFT] > 2100\n",
    "            ):\n",
    "                area_5 = stats[x, cv2.CC_STAT_AREA]\n",
    "                if area_5 > largest_area_5:\n",
    "                    largest_area_5 = area_5\n",
    "                    largest_label_5 = x\n",
    "\n",
    "\n",
    "    if largest_label_1 != -1:\n",
    "        large.append(largest_label_1)\n",
    "        object_presence[0] = 1\n",
    "\n",
    "    if largest_label_2 != -1:\n",
    "        large.append(largest_label_2)\n",
    "        object_presence[1] = 1\n",
    "        \n",
    "    if largest_label_3 != -1:\n",
    "        large.append(largest_label_3)\n",
    "        object_presence[2] = 1\n",
    "    \n",
    "    if largest_label_4 != -1:\n",
    "        large.append(largest_label_4)\n",
    "        object_presence[3] = 1\n",
    "\n",
    "    if largest_label_5 != -1:\n",
    "        large.append(largest_label_5)\n",
    "        object_presence[4] = 1\n",
    "\n",
    "    black_img1 = np.zeros_like(labels, dtype=np.uint8)\n",
    "    for x, component_idx in enumerate(large):\n",
    "        color = x + 1\n",
    "        predicted_root_2[labels == component_idx] = color\n",
    "        black_img1[labels == component_idx] = color\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    w = []\n",
    "    h = []\n",
    "\n",
    "    for i in large:\n",
    "        x.append(stats[i, 0])\n",
    "        y.append(stats[i, 1])\n",
    "        w.append(stats[i, 2])\n",
    "        h.append(stats[i, 3])\n",
    "\n",
    "\n",
    "    full_imgs = []\n",
    "    real_imgs = []\n",
    "\n",
    "\n",
    "    for i in range(len(large)):\n",
    "        full_imgs.append(black_img1[y[i]:y[i]+h[i], x[i]:x[i]+w[i]])\n",
    "        real_imgs.append(img[y[i]:y[i]+h[i], x[i]:x[i]+w[i]])\n",
    "\n",
    "    return(full_imgs, real_imgs, object_presence, x, y, w, h, predicted_root_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_pipeline(img, root_imgs, real_imgs, object_presence, x, y, w, h, predicted_root):\n",
    "    \"\"\"\n",
    "    Executes a small-scale image processing pipeline on a given image.\n",
    "\n",
    "    This function takes an image and applies a series of image processing steps. It first predicts the root presence using an image predictor, and then segments small plants from the image. If objects (plants) are detected, it updates the provided lists with information about these objects, such as their positions and dimensions.\n",
    "\n",
    "    Parameters:\n",
    "    - img (array-like): The image to be processed.\n",
    "    - root_imgs (list): A list of images of roots. This list gets updated with new root images from `img`.\n",
    "    - real_imgs (list): A list of real images. This list gets updated with new real images from `img`.\n",
    "    - object_presence (list): A list indicating the presence of an object in each corresponding image. This list gets updated based on object detection in `img`.\n",
    "    - x (list): A list of x-coordinates of the detected objects. This list gets updated with new coordinates from `img`.\n",
    "    - y (list): A list of y-coordinates of the detected objects. This list gets updated with new coordinates from `img`.\n",
    "    - w (list): A list of widths of the detected objects. This list gets updated with new widths from `img`.\n",
    "    - h (list): A list of heights of the detected objects. This list gets updated with new heights from `img`.\n",
    "\n",
    "    Returns:\n",
    "    Tuple of (root_imgs, real_imgs, object_presence, x, y, w, h): Updated lists containing the image data and object detection details.\n",
    "\n",
    "    Note:\n",
    "    The function relies on external functions `img_predictor` and `small_plant_segmanter`, which are not defined within this function. Ensure these functions are available in the runtime environment for correct operation.\n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_root_1, _ = img_predictor(img=img ,root_thr=0.001, model_type=2)\n",
    "    root_imgs_small, real_imgs_small, object_presence_small, x_small,y_small,w_small,h_small, predicted_root = small_plant_segmanter(predicted_root_1, img, object_presence, predicted_root)\n",
    "\n",
    "    if np.any(object_presence_small == 1):\n",
    "        object_presence_small = np.array(object_presence_small)\n",
    "\n",
    "        indices = np.where(object_presence_small == 1)[0]\n",
    "        for index, value in enumerate(indices):\n",
    "            if object_presence[value] == 0:\n",
    "                object_presence[value] = object_presence_small[value]\n",
    "                root_imgs.insert(value, root_imgs_small[index])\n",
    "                real_imgs.insert(value, real_imgs_small[index])\n",
    "                x.insert(value, x_small[index])\n",
    "                y.insert(value, y_small[index])\n",
    "                w.insert(value, w_small[index])\n",
    "                h.insert(value, h_small[index])\n",
    "    return root_imgs, real_imgs, object_presence, x,y,w,h, predicted_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_length_calc(image, real_img):\n",
    "    \"\"\"\n",
    "    Calculates the length of the longest root in an image using its skeleton representation.\n",
    "\n",
    "    The function performs the following steps:\n",
    "    1. Skeletonize the input image to obtain a simpler representation of the root structure.\n",
    "    2. Summarize the skeleton to identify individual branches.\n",
    "    3. Create a graph representation of the skeleton branches.\n",
    "    4. Find the longest path in the graph, which corresponds to the longest root.\n",
    "    5. Draw circles on the starting and ending points of the longest root on a copy of the original image.\n",
    "    6. Calculate the length of the longest root.\n",
    "    7. Filter and draw the longest root path on a blank or original image.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): A binary image containing the root structure to be analyzed.\n",
    "    real_img (numpy.ndarray): The original image (colored or grayscale) on which the root structure is to be drawn.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the following:\n",
    "        - An image with circles drawn at the start and end points of the longest root.\n",
    "        - The length of the longest root.\n",
    "        - The skeletonized image of the root structure.\n",
    "        - x and y coordinates of the start point of the longest root.\n",
    "        - x and y coordinates of the end point of the longest root.\n",
    "        - An image showing the longest root path.\n",
    "\n",
    "    Note:\n",
    "    The function relies on the following libraries: OpenCV, NetworkX, and NumPy. Ensure these are installed and imported as cv2, nx, and np, respectively.\n",
    "    \"\"\"\n",
    "    skeleton = skeletonize(image)\n",
    "    skeleton_branch = summarize(Skeleton(skeleton))\n",
    "    G = nx.from_pandas_edgelist(skeleton_branch, source='node-id-src', target='node-id-dst', edge_attr='branch-distance')\n",
    "\n",
    "    x_start = []\n",
    "    y_start = []\n",
    "    x_end = []\n",
    "    y_end = []\n",
    "\n",
    "    branches = len(skeleton_branch)\n",
    "    im_with_circles = real_img.copy()\n",
    "    end_root_index = skeleton_branch[\"node-id-dst\"].nsmallest(branches).iloc[-1]\n",
    "\n",
    "    for i in range(branches):\n",
    "        if i == 0:\n",
    "            x_start = skeleton_branch[\"image-coord-src-0\"][i]\n",
    "            y_start = skeleton_branch[\"image-coord-src-1\"][i]\n",
    "            im_with_circles = cv2.circle(im_with_circles, (y_start, x_start), 10, (0, 255, 0), 2)\n",
    "            start_node = skeleton_branch[\"node-id-src\"][i]\n",
    "            if branches == 1:\n",
    "                x_end = skeleton_branch[\"image-coord-dst-0\"][i]\n",
    "                y_end = skeleton_branch[\"image-coord-dst-1\"][i]\n",
    "                im_with_circles = cv2.circle(im_with_circles, (y_end, x_end), 10, (0, 0, 0), 2)\n",
    "                end_node = skeleton_branch[\"node-id-dst\"][i]\n",
    "        else:\n",
    "            if skeleton_branch[\"node-id-dst\"][i] == end_root_index:\n",
    "                x_end = skeleton_branch[\"image-coord-dst-0\"][i]\n",
    "                y_end = skeleton_branch[\"image-coord-dst-1\"][i]\n",
    "                im_with_circles = cv2.circle(im_with_circles, (y_end, x_end), 10, (0, 0, 0), 2)\n",
    "                end_node = skeleton_branch[\"node-id-dst\"][i]\n",
    "    \n",
    "    root_len = nx.dijkstra_path_length(G, end_node, start_node, weight='branch-distance')\n",
    "    shortest_path = nx.dijkstra_path(G, source=start_node, target=end_node, weight='branch-distance')\n",
    "    \n",
    "    shortest_edges = [(shortest_path[i], shortest_path[i+1]) for i in range(len(shortest_path)-1)]\n",
    "    filtered_branches = skeleton_branch[skeleton_branch.apply(lambda row: (row['node-id-src'], row['node-id-dst']) in shortest_edges, axis=1)]\n",
    "    \n",
    "    filtered_skeleton_image = np.zeros_like(real_img)\n",
    "\n",
    "    for index, row in filtered_branches.iterrows():\n",
    "        src = (int(row['image-coord-src-1']), int(row['image-coord-src-0']))  # y, x for source\n",
    "        dst = (int(row['image-coord-dst-1']), int(row['image-coord-dst-0']))  # y, x for destination\n",
    "        filtered_skeleton_image = cv2.line(filtered_skeleton_image, src, dst, color=(255, 255, 255), thickness=6)\n",
    "\n",
    "    return im_with_circles, root_len, skeleton, x_start, y_start, x_end, y_end, filtered_skeleton_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_feeder(img):\n",
    "    \"\"\"\n",
    "    Processes an image to identify root structures, calculate their lengths, and visualize the results.\n",
    "\n",
    "    This function performs several steps to analyze root structures in an input image:\n",
    "    1. Depending on the size of the input image, it either fixes errors or crops the image.\n",
    "    2. Predicts root locations in the processed image.\n",
    "    3. Segments the image to isolate individual roots and their corresponding real images.\n",
    "    4. If necessary, applies a smaller pipeline for further processing.\n",
    "    5. For each detected root, calculates its length and generates a visual representation of the root skeleton.\n",
    "    6. Overlays the skeleton on the original image, highlighting the start and end points of each root.\n",
    "\n",
    "    Parameters:\n",
    "    img (numpy.ndarray): The input image to be processed. It should be a grayscale or colored image of root structures.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the following:\n",
    "        - A list of images with circles drawn at the start and end points of each root.\n",
    "        - A list of the lengths of each identified root.\n",
    "        - An image with the combined visualizations of all roots, their skeletons, and start/end points marked.\n",
    "\n",
    "    Note:\n",
    "    This function depends on several other functions (`error_fix`, `crop_img`, `img_predictor`, `segmanter`, `small_pipeline`, `root_length_calc`) and external libraries such as OpenCV and NumPy. Ensure all dependent functions and libraries are available and properly imported.\n",
    "    \"\"\"\n",
    "    if img.shape[0] < 3000:\n",
    "        cropped_img = error_fix(img)\n",
    "    else:\n",
    "        cropped_img = crop_img(img)\n",
    "    predicted_root, output_img = img_predictor(cropped_img, root_thr=0.05, model_type=2)\n",
    "    root_imgs, real_imgs, object_presence, x, y, w, h, predicted_root = segmanter(predicted_root, output_img)\n",
    "\n",
    "    if np.any(object_presence == 0):\n",
    "        root_imgs, real_imgs, object_presence, x, y, w, h, predicted_root = small_pipeline(cropped_img, root_imgs, real_imgs, object_presence, x, y, w, h, predicted_root)\n",
    "\n",
    "    cirles = []\n",
    "    root_lens = []\n",
    "    skeletons = []\n",
    "    filtered_skeleton_images = []\n",
    "    \n",
    "    end_img = output_img.copy()\n",
    "    red_color = (0, 0, 255)\n",
    "    end_img = cv2.cvtColor(end_img, cv2.COLOR_GRAY2BGR)\n",
    " \n",
    "    i = 0\n",
    "    for object in object_presence:\n",
    "        if object == 1:\n",
    "            circle, root_len, skeleton, y_s, x_s, y_e, x_e, filtered_skeleton_image = root_length_calc(root_imgs[i], real_imgs[i])\n",
    "            cirles.append(circle)\n",
    "            skeletons.append(skeleton)\n",
    "            root_lens.append(root_len)\n",
    "            filtered_skeleton_images.append(filtered_skeleton_image)\n",
    "\n",
    "            x_start = x[i] + x_s\n",
    "            y_start = y[i] + y_s\n",
    "            x_end = x[i] + x_e\n",
    "            y_end = y[i] + y_e\n",
    "\n",
    "            filtered_skeleton_image_color = cv2.cvtColor(filtered_skeleton_image, cv2.COLOR_GRAY2BGR)\n",
    "            other_image_color = cv2.cvtColor(real_imgs[i], cv2.COLOR_GRAY2BGR)\n",
    "            filtered_skeleton_image_color[filtered_skeleton_image == 255] = red_color\n",
    "\n",
    "            combined_image = cv2.add(filtered_skeleton_image_color, other_image_color)\n",
    "            end_img[y[i]:y[i]+h[i], x[i]:x[i]+w[i]] = combined_image\n",
    "            end_img = cv2.circle(end_img, (x_start, y_start), 50, (0, 255, 0), 6)  \n",
    "            end_img = cv2.circle(end_img, (x_end, y_end), 50, (0, 0, 0), 6)  \n",
    "            i += 1\n",
    "        else:\n",
    "            root_lens.append(0)\n",
    "    return cirles, root_lens, end_img, predicted_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_handler(dir):\n",
    "    \"\"\"\n",
    "    Processes all image files in a specified directory for root structure analysis.\n",
    "\n",
    "    This function iterates through each image file in the given directory, analyzes the root structures in each image,\n",
    "    and compiles the results. It handles images with specific file extensions, reads them, and uses the `img_feeder`\n",
    "    function to process each image.\n",
    "\n",
    "    Steps:\n",
    "    1. Sorts the files in the directory based on a naming convention.\n",
    "    2. For each sorted image file, reads the image and processes it using `img_feeder`.\n",
    "    3. Collects and aggregates the results from all images.\n",
    "\n",
    "    Parameters:\n",
    "    dir (str): The directory path containing the image files to be processed.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the following:\n",
    "        - A list of images with visualized root structures for each file.\n",
    "        - A list of root lengths for each root identified across all files.\n",
    "        - A list of end images with combined visualizations for each file.\n",
    "\n",
    "    Note:\n",
    "    The function expects image files to follow a specific naming convention for sorting (e.g., based on a number in the filename).\n",
    "    Supported file formats are .tif and .png. This function depends on the `img_feeder` function and external libraries like OpenCV and os.\n",
    "    \"\"\"\n",
    "    circle_imgs = []\n",
    "    root_lens = []\n",
    "    end_imgs = []\n",
    "    data = []\n",
    "    i = 1\n",
    "    #file_names_sorted = sorted(os.listdir(dir), key=lambda x: int(x.split('_')[2].split('.')[0]))\n",
    "    file_names_sorted = os.listdir(dir)\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    for img_file in file_names_sorted:\n",
    "        if img_file.endswith(\".tif\") or img_file.endswith(\".png\"):\n",
    "            img = cv2.imread(f\"{dir}/{img_file}\", 0)\n",
    "            try:\n",
    "                circle_img, root_len, end_img, predicted_root = img_feeder(img)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "            circle_imgs.extend(circle_img)\n",
    "            root_lens.extend(root_len)\n",
    "            end_imgs.append(end_img)\n",
    "            for j, length in enumerate(root_len):\n",
    "                row_value = f\"test_image_{i}_plant_{j + 1}\"\n",
    "                data.append([row_value, length])\n",
    "            cv2.imwrite(f\"outputs/{img_file}\", predicted_root)\n",
    "            i += 1\n",
    "    df = pd.DataFrame(data, columns=['Plant ID', 'Length (px)'])\n",
    "    df.to_csv(Save_results_as, index=False)\n",
    "    return(circle_imgs, root_lens, end_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(actual, forecast):\n",
    "    if np.array_equal(actual, forecast):\n",
    "        print(\"The arrays are identical.\")\n",
    "        return 0\n",
    "    else:\n",
    "        denominator = (np.abs(actual) + np.abs(forecast)) / 2\n",
    "        diff = np.abs(forecast - actual) / denominator\n",
    "        diff[denominator == 0] = 0.0 \n",
    "        return 100 * np.mean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(circle_ims):\n",
    "    leng = int(len(circle_ims)/5)\n",
    "    fig, ax = plt.subplots(leng, 5, dpi=250)\n",
    "    x = 0\n",
    "    for i in range(leng):\n",
    "        ax[i, 0].imshow(circle_ims[x])\n",
    "        ax[i, 0].axis('off')\n",
    "        ax[i, 1].imshow(circle_ims[x + 1])\n",
    "        ax[i, 1].axis('off')\n",
    "        ax[i, 2].imshow(circle_ims[x + 2])\n",
    "        ax[i, 2].axis('off')\n",
    "        ax[i, 3].imshow(circle_ims[x + 3])\n",
    "        ax[i, 3].axis('off')\n",
    "        ax[i, 4].imshow(circle_ims[x + 4])\n",
    "        ax[i, 4].axis('off')\n",
    "        x += 5\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circles, root_lens, end_imgs = folder_handler(Input_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
