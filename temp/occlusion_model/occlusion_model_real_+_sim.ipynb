{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padder(image, patch_size):\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "    height_padding = ((h // patch_size) + 1) * patch_size - h\n",
    "    width_padding = ((w // patch_size) + 1) * patch_size - w\n",
    "\n",
    "    top_padding = int(height_padding/2)\n",
    "    bottom_padding = height_padding - top_padding\n",
    "\n",
    "    left_padding = int(width_padding/2)\n",
    "    right_padding = width_padding - left_padding\n",
    "\n",
    "    padded_image = cv2.copyMakeBorder(image, top_padding, bottom_padding, left_padding, right_padding, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data in patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths and directories\n",
    "patch_dir = 'real_plus_sim_data/data_patched_256'\n",
    "\n",
    "# Define patch size\n",
    "patch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for the training set\n",
    "train_image_datagen = ImageDataGenerator(rescale=1./255, \n",
    "    horizontal_flip=True,  # Add horizontal flip for augmentation\n",
    "    vertical_flip=True                                     \n",
    ")\n",
    "\n",
    "train_image_generator = train_image_datagen.flow_from_directory(\n",
    "    f'{patch_dir}/train_masks',\n",
    "    target_size=(patch_size, patch_size),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    seed=42)\n",
    "\n",
    "# Training masks\n",
    "train_mask_datagen = ImageDataGenerator(rescale=1./255, \n",
    "    horizontal_flip=True,  # Add horizontal flip for augmentation\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "train_mask_generator = train_mask_datagen.flow_from_directory(\n",
    "    f'{patch_dir}/train_images',\n",
    "    target_size=(patch_size, patch_size),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    seed=42)\n",
    "\n",
    "train_generator = zip(train_image_generator, train_mask_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for the test set\n",
    "val_image_datagen = ImageDataGenerator(rescale=1./255,    \n",
    "                                       horizontal_flip=True,  # Add horizontal flip for augmentation\n",
    "    vertical_flip=True  # Add horizontal flip for augmentation\n",
    ")\n",
    "\n",
    "val_image_generator = val_image_datagen.flow_from_directory(\n",
    "    f'{patch_dir}/val_masks',\n",
    "    target_size=(patch_size, patch_size),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    seed=42)\n",
    "\n",
    "# Test masks\n",
    "val_mask_datagen = ImageDataGenerator(rescale=1./255,  \n",
    "    horizontal_flip=True,  # Add horizontal flip for augmentation\n",
    "    vertical_flip=True  # Add horizontal flip for augmentation\n",
    ")\n",
    "\n",
    "val_mask_generator = val_mask_datagen.flow_from_directory(\n",
    "    f'{patch_dir}/val_images',\n",
    "    target_size=(patch_size, patch_size),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    seed=42)\n",
    "\n",
    "val_generator = zip(val_image_generator, val_mask_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for the test set\n",
    "test_image_datagen = ImageDataGenerator()\n",
    "\n",
    "test_image_generator = test_image_datagen.flow_from_directory(\n",
    "    f'{patch_dir}/test_masks',\n",
    "    target_size=(patch_size, patch_size),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    seed=42)\n",
    "\n",
    "# Test masks\n",
    "test_mask_datagen = ImageDataGenerator()\n",
    "\n",
    "test_mask_generator = test_mask_datagen.flow_from_directory(\n",
    "    f'{patch_dir}/test_images',\n",
    "    target_size=(patch_size, patch_size),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    seed=42)\n",
    "\n",
    "test_generator = zip(test_image_generator, test_mask_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's implement two custom metrics f1 score and iou\n",
    "def f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = TP / (Positives+K.epsilon())\n",
    "        return recall\n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        threshold = 0.5 \n",
    "        y_pred_binary = K.round(y_pred + 0.5 - threshold)\n",
    "        \n",
    "        intersection = K.sum(K.abs(y_true * y_pred_binary), axis=[1,2,3])\n",
    "        total = K.sum(K.square(y_true), [1,2,3]) + K.sum(K.square(y_pred_binary), [1,2,3])\n",
    "        union = total - intersection\n",
    "        return (intersection + K.epsilon()) / (union + K.epsilon())\n",
    "    \n",
    "    return K.mean(f(y_true, y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net model\n",
    "# Author: Sreenivas Bhattiprolu\n",
    "# This code is coming from the videos at the beginning\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "\n",
    "def simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):\n",
    "# Build the model\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = inputs\n",
    "\n",
    "    # Contraction path\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    \n",
    "    # Expansive path \n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "     \n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "     \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', f1, iou])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the model\n",
    "model = simple_unet_model(patch_size, patch_size, 1)\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_f1', mode = 'max', patience=35, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('occlusion_rs_1_256.h5', monitor='val_f1', mode = 'max', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.device('/GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_image_generator),  # Use len(train_image_generator) instead\n",
    "    epochs=400,  # Adjust the number of epochs as needed\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_image_generator),  # Use len(val_image_generator) instead\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "score = model.evaluate(test_generator, steps=len(test_image_generator))\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Test Loss: {score[0]}')\n",
    "print(f'Test Accuracy: {score[1]}')\n",
    "print(f'Test F1 Score: {score[2]}')\n",
    "print(f'Test IoU: {score[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "model.save(f\"occlusion_rs_1_256.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the best model saved during training, providing custom metrics\n",
    "model = load_model(\"occlusion_rs_1_256.h5\", custom_objects={'f1': f1, 'iou': iou})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_in_folder(folder_path, num_images):\n",
    "    # Get a list of all image files in the specified folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.tif', '.jpeg'))]\n",
    "\n",
    "    # Select a random sample of image files\n",
    "    selected_files = np.random.choice(image_files, num_images, replace=False)\n",
    "\n",
    "    for image_file in selected_files:\n",
    "        # Construct the full path of the image file\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "\n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Apply your existing code\n",
    "        #patch_size = 512\n",
    "        image = padder(image, patch_size)\n",
    "        patches = patchify(image, (patch_size, patch_size), step=patch_size)\n",
    "        i, j = patches.shape[0], patches.shape[1]\n",
    "        patches = patches.reshape(-1, patch_size, patch_size, 1)\n",
    "        preds = model.predict(patches / 255)\n",
    "        preds = preds.reshape(i, j, patch_size, patch_size)\n",
    "        predicted_mask = unpatchify(preds, (image.shape[0], image.shape[1]))\n",
    "        predicted_mask = predicted_mask > 0.5\n",
    "\n",
    "        # Plot the images with the image file name as the title\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(11, 6))\n",
    "        ax[0].imshow(image, cmap=\"gray\")\n",
    "        ax[1].imshow(predicted_mask, cmap=\"gray\")\n",
    "        ax[0].axis(\"off\")\n",
    "        ax[0].set_title(\"Original image\")\n",
    "        ax[1].axis(\"off\")\n",
    "        ax[1].set_title(f\"Predicted root mask - {image_file}\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'p_w'\n",
    "num_images = 1\n",
    "\n",
    "process_images_in_folder(folder_path, num_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "def process_images_in_folder(folder_path, num_images, refinement_steps=5):\n",
    "    # Get a list of all image files in the specified folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.tif', '.jpeg'))]\n",
    "\n",
    "    # Select a random sample of image files\n",
    "    selected_files = np.random.choice(image_files, num_images, replace=False)\n",
    "\n",
    "    for image_file in selected_files:\n",
    "        # Construct the full path of the image file\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "\n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Assume 'padder' function is defined elsewhere to adjust image dimensions as needed\n",
    "        #patch_size = 512\n",
    "        image = padder(image, patch_size)  # Assuming 'padder' adjusts the image size as required\n",
    "        patches = patchify(image, (patch_size, patch_size), step=patch_size)\n",
    "        i, j = patches.shape[0], patches.shape[1]\n",
    "        patches = patches.reshape(-1, patch_size, patch_size, 1)\n",
    "\n",
    "        # Initial prediction\n",
    "        preds = model.predict(patches / 255)\n",
    "        \n",
    "        # Iteratively refine predictions\n",
    "        for _ in range(refinement_steps):\n",
    "            # Reshape predictions to match the patches layout, then predict again\n",
    "            refined_patches = preds.reshape(-1, patch_size, patch_size, 1)\n",
    "            preds = model.predict(refined_patches)\n",
    "            preds = preds > 0.5  # Apply threshold to get binary mask\n",
    "\n",
    "        # Final processing of predictions\n",
    "        preds = preds.reshape(i, j, patch_size, patch_size)\n",
    "        predicted_mask = unpatchify(preds, (image.shape[0], image.shape[1]))\n",
    "        #predicted_mask = predicted_mask > 0.5  # Apply threshold to get binary mask\n",
    "\n",
    "        # Plot the images with the image file name as the title\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(11, 6))\n",
    "        ax[0].imshow(image, cmap=\"gray\")\n",
    "        ax[1].imshow(predicted_mask, cmap=\"gray\")\n",
    "        ax[0].axis(\"off\")\n",
    "        ax[0].set_title(\"Original image\")\n",
    "        ax[1].axis(\"off\")\n",
    "        ax[1].set_title(f\"Predicted root mask - {image_file}\")\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'p_w'\n",
    "num_images = 1\n",
    "\n",
    "process_images_in_folder(folder_path, num_images, refinement_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'real_occlusions_test_images'\n",
    "num_images = 32\n",
    "\n",
    "process_images_in_folder(folder_path, num_images, refinement_steps=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
