{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "from skimage.morphology import skeletonize\n",
    "from skan import Skeleton, summarize\n",
    "from skan.csr import skeleton_to_csgraph\n",
    "from skan import draw\n",
    "import skan\n",
    "from skimage.morphology import skeletonize\n",
    "import networkx as nx\n",
    "\n",
    "from metrics import f1,iou\n",
    "from backend import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If folder 'input' exists populate with images, if not run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('input') == False:\n",
    "    os.mkdir('input')\n",
    "    print('Please populate the input folder with the images to be processed then rerun script!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'plants' already exists.\n",
      "Folder 'model_refrence' already exists.\n"
     ]
    }
   ],
   "source": [
    "# Create all required folders if not existent\n",
    "create_folder('plants')\n",
    "create_folder('model_refrence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models\n",
    "root_segmentation_model = tf.keras.models.load_model('model_refrence/root_4_ss.h5', custom_objects={'f1': f1,'iou':iou})\n",
    "patching_model = tf.keras.models.load_model('model_refrence/discontinuity_patcher.h5', custom_objects={'f1': f1,'iou':iou})\n",
    "shoot_segmentation_model = tf.keras.models.load_model('model_refrence/shoot_exp_1.h5', custom_objects={'f1': f1,'iou':iou})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ROI(region of interest) from the image\n",
    "for filename in os.listdir('input'):\n",
    "    original_image = cv2.imread('input/' + filename)\n",
    "    min_x, max_x, min_y, max_y = roi_extraction_coords('input/' + filename)\n",
    "    roi_extracted_image = set_outside_pixels_to_zero(original_image, min_x, max_x, min_y, max_y)\n",
    "    filename = filename.replace('.tif', '.png')\n",
    "    cv2.imwrite('input/' + filename, roi_extracted_image)  # Save the extracted ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model predictions (each image has its own sub-folder)\n",
    "save_model_predictions('input', root_segmentation_model, patching_model, shoot_segmentation_model, padder, 'plants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image to overlay the root and shoot masks (saves the image in the same folder)\n",
    "overlay_root_shoot_masks('plants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(root_mask)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, retval), mask_values):\n\u001b[1;32m---> 20\u001b[0m     mask[labels \u001b[38;5;241m==\u001b[39m label] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Apply the mask to the original root mask to get the final image\u001b[39;00m\n\u001b[0;32m     23\u001b[0m final_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mbitwise_and(root_mask, root_mask, mask\u001b[38;5;241m=\u001b[39mmask)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterate through each subfolder in the 'plants' folder\n",
    "for subdir, dirs, files in os.walk('plants'):\n",
    "    for file in files:\n",
    "        # Check if the file is a root mask image\n",
    "        if file.endswith(\"_root_mask.png\"):\n",
    "            root_mask_path = os.path.join(subdir, file)\n",
    "            root_mask = cv2.imread(root_mask_path, cv2.IMREAD_GRAYSCALE)  # Read the mask image in grayscale\n",
    "\n",
    "            # Connected components labeling on the root mask\n",
    "            retval, labels, stats, centroids = cv2.connectedComponentsWithStats(root_mask)\n",
    "\n",
    "            # Create a mask to retain only regions with area above the threshold\n",
    "            mask_values = [255 if (stats[label, cv2.CC_STAT_TOP] < 800 and\n",
    "                                   stats[label, cv2.CC_STAT_TOP] > 300) else 0\n",
    "                           for label in range(1, retval)]\n",
    "\n",
    "            # Apply the mask values to create a new mask\n",
    "            mask = np.zeros_like(root_mask)\n",
    "            for label, value in zip(range(1, retval), mask_values):\n",
    "                mask[labels == label] = value\n",
    "\n",
    "            # Apply the mask to the original root mask to get the final image\n",
    "            final_image = cv2.bitwise_and(root_mask, root_mask, mask=mask)\n",
    "            final_image = final_image[min_x:max_x, min_y:max_y]\n",
    "\n",
    "            # Extract and save ROIs based on the final image\n",
    "            for i in range(11):\n",
    "                start_col = i * final_image.shape[1] // 5\n",
    "                end_col = (i + 1) * final_image.shape[1] // 5\n",
    "                roi = final_image[:,start_col:end_col]\n",
    "                # Save each ROI with a sequential number\n",
    "                roi_filename = f\"roi_{i+1}.png\"  # Naming each ROI sequentially\n",
    "                roi_path = os.path.join(subdir, roi_filename)\n",
    "                if np.count_nonzero(roi) != 0:\n",
    "                    skeletonized_roi = skeletonize(roi)\n",
    "                    skeleton_graph = skan.summarize(Skeleton(skeletonized_roi))\n",
    "                    num_skeletons = len(skeleton_graph['skeleton-id'].unique())\n",
    "                    cv2.imwrite(roi_path, roi)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir('plants'):\n",
    "    measure_images_in_folder('plants/' + folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
